{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **What is a random variable in probability theory?**\n",
        "   - A random variable is a variable whose possible values are numerical outcomes of a random phenomenon. It maps outcomes from a random experiment to numbers, providing a way to quantify the uncertainty of events.\n",
        "\n",
        "2. **What are the types of random variables?**\n",
        "   - There are two main types of random variables:\n",
        "     - **Discrete Random Variables**: These take on a finite or countably infinite number of values. Examples: number of heads in coin flips, number of cars in a parking lot.\n",
        "     - **Continuous Random Variables**: These can take any value within a given range or interval. Examples: height, weight, time.\n",
        "\n",
        "3. **What is the difference between discrete and continuous distributions?**\n",
        "   - **Discrete distributions** are for random variables that can take only specific, distinct values (e.g., binomial, Poisson distributions). The probability mass function (PMF) gives the probabilities for these discrete outcomes.\n",
        "   - **Continuous distributions** are for random variables that can take any value within a continuous range (e.g., normal, uniform distributions). The probability density function (PDF) describes the likelihood of any given outcome within that range.\n",
        "\n",
        "4. **What are probability distribution functions (PDF)?**\n",
        "   - A **Probability Distribution Function (PDF)** is a function that describes the likelihood of different outcomes for a continuous random variable. The area under the curve of a PDF over a given range represents the probability that the random variable falls within that range.\n",
        "\n",
        "5. **How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?**\n",
        "   - A **CDF** gives the probability that a random variable is less than or equal to a particular value. It is the cumulative sum of the probabilities for all outcomes less than or equal to the given value.\n",
        "   - A **PDF** describes the likelihood of a specific value occurring in a continuous random variable, whereas the CDF represents the cumulative probability up to that point.\n",
        "\n",
        "6. **What is a discrete uniform distribution?**\n",
        "   - A **discrete uniform distribution** is a distribution where a finite set of outcomes all have the same probability. For example, when rolling a fair die, each of the six faces has a probability of 1/6.\n",
        "\n",
        "7. **What are the key properties of a Bernoulli distribution?**\n",
        "   - The **Bernoulli distribution** describes a random variable with two possible outcomes: 1 (success) or 0 (failure). It is characterized by a single parameter \\( p \\), which is the probability of success. The distribution is used to model binary outcomes, like yes/no or true/false questions.\n",
        "\n",
        "8. **What is the binomial distribution, and how is it used in probability?**\n",
        "   - The **binomial distribution** models the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success \\( p \\). It is used to calculate the probability of getting exactly \\( k \\) successes in \\( n \\) trials.\n",
        "\n",
        "9. **What is the Poisson distribution and where is it applied?**\n",
        "   - The **Poisson distribution** models the number of events occurring in a fixed interval of time or space, where events happen independently and at a constant rate. It is often used in modeling rare events, such as accidents or phone call arrivals.\n",
        "\n",
        "10. **What is a continuous uniform distribution?**\n",
        "    - A **continuous uniform distribution** is a distribution where all outcomes in a given interval are equally likely. The PDF is flat over the range of possible values, meaning each value has the same probability of occurring.\n",
        "\n",
        "11. **What are the characteristics of a normal distribution?**\n",
        "    - A **normal distribution** is symmetric, bell-shaped, and characterized by two parameters: the mean (μ) and the standard deviation (σ). It describes many natural phenomena, such as heights, test scores, and errors in measurements.\n",
        "\n",
        "12. **What is the standard normal distribution, and why is it important?**\n",
        "    - The **standard normal distribution** is a normal distribution with a mean of 0 and a standard deviation of 1. It is important because it serves as a reference distribution, and any normal distribution can be transformed into the standard normal distribution using Z-scores.\n",
        "\n",
        "13. **What is the Central Limit Theorem (CLT), and why is it critical in statistics?**\n",
        "    - The **Central Limit Theorem** states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the shape of the original distribution. It is critical because it enables the use of normal distribution approximations for many statistical analyses, even when the underlying distribution is not normal.\n",
        "\n",
        "14. **How does the Central Limit Theorem relate to the normal distribution?**\n",
        "    - The CLT ensures that as the sample size increases, the sampling distribution of the sample mean becomes approximately normal, regardless of the shape of the population distribution. This allows for the application of normal distribution techniques to infer properties about the population from sample data.\n",
        "\n",
        "15. **What is the application of Z statistics in hypothesis testing?**\n",
        "    - Z-statistics are used in hypothesis testing to determine how far a sample statistic (e.g., sample mean) is from the population parameter (e.g., population mean) in terms of standard errors. It helps to assess whether a sample is consistent with a null hypothesis.\n",
        "\n",
        "16. **How do you calculate a Z-score, and what does it represent?**\n",
        "    - A **Z-score** is calculated as \\( Z = \\frac{X - \\mu}{\\sigma} \\), where \\( X \\) is the value, \\( \\mu \\) is the mean, and \\( \\sigma \\) is the standard deviation. It represents the number of standard deviations a value is away from the mean.\n",
        "\n",
        "17. **What are point estimates and interval estimates in statistics?**\n",
        "    - A **point estimate** is a single value estimate of a population parameter, such as the sample mean being used to estimate the population mean.\n",
        "    - An **interval estimate** is a range of values, typically represented by a confidence interval, that likely contains the population parameter.\n",
        "\n",
        "18. **What is the significance of confidence intervals in statistical analysis?**\n",
        "    - **Confidence intervals** provide a range of values within which the true population parameter is likely to lie, with a certain level of confidence (e.g., 95%). They give more information than point estimates, as they indicate the uncertainty around the estimate.\n",
        "\n",
        "19. **What is the relationship between a Z-score and a confidence interval?**\n",
        "    - The Z-score is used to construct confidence intervals. For example, in a 95% confidence interval, the Z-score is typically 1.96, meaning the interval extends 1.96 standard deviations above and below the sample mean.\n",
        "\n",
        "20. **How are Z-scores used to compare different distributions?**\n",
        "    - Z-scores standardize different distributions, allowing comparisons even if the distributions have different means or standard deviations. By converting values to Z-scores, we can compare how far data points are from their respective means in terms of standard deviations.\n",
        "\n",
        "21. **What are the assumptions for applying the Central Limit Theorem?**\n",
        "    - The assumptions for the CLT include:\n",
        "      - The random variables are independent.\n",
        "      - The random variables are identically distributed.\n",
        "      - The sample size is sufficiently large (usually \\( n > 30 \\)).\n",
        "\n",
        "22. **What is the concept of expected value in a probability distribution?**\n",
        "    - The **expected value** (or mean) is the long-run average or central value of a random variable. It is calculated by summing the weighted outcomes, where each outcome is weighted by its probability.\n",
        "\n",
        "23. **How does a probability distribution relate to the expected outcome of a random variable?**\n",
        "    - The probability distribution describes all possible outcomes of a random variable and their probabilities. The expected value is the average or \"expected\" outcome, calculated by taking the weighted sum of all possible values, weighted by their probabilities."
      ],
      "metadata": {
        "id": "naxPRUyNMn5l"
      }
    }
  ]
}